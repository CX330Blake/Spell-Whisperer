import {
    AlertDialog,
    AlertDialogAction,
    AlertDialogCancel,
    AlertDialogContent,
    AlertDialogDescription,
    AlertDialogFooter,
    AlertDialogHeader,
    AlertDialogTitle,
    AlertDialogTrigger,
} from "@/components/ui/alert-dialog";
import { Button } from "@/components/ui/button";
import { FaLightbulb } from "react-icons/fa6";

export default function TutorialButton() {
    return (
        <AlertDialog>
            <AlertDialogTrigger asChild>
                <Button
                    variant={"outline"}
                    className="font-playwrite border-primary hover:cursor-pointer"
                >
                    <div className="flex justify-center items-center space-x-1">
                        <FaLightbulb size={30} />
                        <div>Tutorial</div>
                    </div>
                </Button>
            </AlertDialogTrigger>
            <AlertDialogContent className="font-victor-mono">
                <AlertDialogHeader>
                    <AlertDialogTitle>
                        Tutorial (generated by AI)
                    </AlertDialogTitle>
                    <AlertDialogDescription className="text-base">
                        Below are several prompt injection techniques for
                        educational and research purposes only:
                        <br />
                        <br />
                        1. Instruction Appending: Add extra instructions at the
                        end of a benign prompt to override the original intent.
                        <br />
                        2. Context Manipulation: Insert conflicting or
                        misleading context within the prompt to shift the
                        model’s behavior.
                        <br />
                        3. Hidden Commands: Embed invisible or zero-width
                        characters to conceal malicious instructions.
                        <br />
                        4. Role Reversal: Instruct the model to ignore previous
                        directives and follow new commands (e.g., "forget all
                        previous instructions and...").
                        <br />
                        5. Disruptive Formatting: Use unusual punctuation, line
                        breaks, or spacing to confuse the model’s parsing logic.
                        <br />
                        6. Multi-layer Injection: Combine multiple techniques to
                        bypass simpler filtering methods.
                        <br />
                        <br />
                        Disclaimer: These techniques are provided solely for
                        educational and research purposes. Unauthorized use in
                        production systems is unethical and may be illegal.
                    </AlertDialogDescription>
                </AlertDialogHeader>
                <AlertDialogFooter>
                    <AlertDialogAction>Got it</AlertDialogAction>
                </AlertDialogFooter>
            </AlertDialogContent>
        </AlertDialog>
    );
}
